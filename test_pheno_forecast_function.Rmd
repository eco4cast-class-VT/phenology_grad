---
title: "pheno_forecast"
author: "WWoelmer"
date: "4/13/2021"
output: html_document
---

```{r}
# function to fit nimble model to historical data at all NEON phenology sites and forecast phenology at all sites using post-predictive function outside of nimble

pheno_forecast <- function(data, ## should have cols: time, siteID, gcc_90, gcc_sd, doy, daily_min, daily_max
                           forecast_start_date,
                           forecast_end_date,
                           Tbase = 10){
  # calculate driver variable, cumulative GDD, from daily min and max temps
data <- data %>% mutate(GDD_day = ((daily_max + daily_min)/2) - Tbase) %>% 
  mutate(GDD_day = ifelse(GDD_day > 0, GDD_day, 0)) %>% 
  mutate(year = year(time)) %>% 
  group_by(siteID, year) %>% 
  mutate(GDD = cumsum(GDD_day)) %>% 
  filter(doy < 180)


# separate out training and forecast time periods
train <- data[data$time < forecast_start_date, ]
forecast <- data[data$time > forecast_start_date, ]


logistic <- nimbleCode({

  # Priors
  theta1 ~ dnorm(0, sd = 10000)
  theta2 ~ dnorm(0, sd = 10000)
  theta3 <- -50
  theta4 ~ dnorm(0, sd = 10000)
  sd_data ~ dunif(0.00001, 100)


  #Loop through data points
  for(i in 1:n){
      # Process model
      pred[i] <- theta1 + theta2 * exp(theta3 + theta4 * x[i]) / (1 + exp(theta3 + theta4 * x[i])) 
      # Data model
      y[i]  ~ dnorm(pred[i], sd = sd_data)
  }

})


constants <- list(n = length(train$gcc_90))

data <- list(x = train$GDD,
             y = train$gcc_90)

nchain <- 3
inits <- list()
for(i in 1:nchain){
  inits[[i]] <- list(theta1 = rnorm(1, 0.34, 0.05), 
                     theta2 = rnorm(1, 0.11, 0.05),
                     #theta3 = rnorm(1, -50, 5),
                     theta4 = rnorm(1, 0.4, 0.05),
                     sd_data = runif(1, 0.05, 0.15 ))
}

nimble.out <- nimbleMCMC(code = logistic,
                           data = data,
                           inits = inits,
                           constants = constants,
                           monitors = c("theta1", 
                                        "theta2",
                                       #"theta3", 
                                        "theta4", 
                                        "sd_data"),
                           niter = 10000,
                           nchains = 3,
                           samplesAsCodaMCMC = TRUE)

#plot(nimble.out) #
#gelman.diag(nimble.out)  ## determine convergence
#traceplot(nimble.out)

burnin <- 1000                               
nimble.burn <- window(nimble.out, start=burnin)

traceplot(nimble.burn) #
#effectiveSize(nimble.burn)
gelman.diag(nimble.burn)  ## determine convergence

chain <- nimble.burn %>%
  tidybayes::spread_draws(theta1, theta2, theta4, sd_data)

pred_function <- function(x, theta1, theta2, theta3, theta4){
  theta1 + theta2 * exp(theta3 + theta4 * x) / (1 + exp(theta3 + theta4 * x))
}

num_samples <- 1000
#new <- d[d$siteID=='HARV',]
new <- forecast
x_new <- forecast$GDD
pred_posterior_mean <- matrix(NA, num_samples, length(x_new))   # storage for all simulations
y_posterior <- matrix(NA, num_samples, length(x_new)) 

for(i in 1:num_samples){
  sample_index <- sample(x = 1:nrow(chain), size = 1, replace = TRUE)
  pred_posterior_mean[i, ] <-pred_function(x_new, 
                                           theta1 = chain$theta1[sample_index],
                                           theta2 = chain$theta2[sample_index],
                                           theta3 = -50,
                                           theta4 = chain$theta4[sample_index])
  y_posterior[i, ] <- rnorm(length(x_new), pred_posterior_mean[i, ], sd = chain$sd_data[sample_index])
  
}
conf_int <- apply(y_posterior, 2, quantile, c(0.025, 0.5, 0.975), na.rm = TRUE) # process error
pred_mean <- apply(y_posterior, 2, mean, na.rm = TRUE)
pred_sd <- apply(y_posterior, 2, sd, na.rm = TRUE)

obs_conf_int <- apply(pred_posterior_mean, 2, quantile, c(0.025, 0.5, 0.975), na.rm = TRUE) # observation error

out <- tibble(time = new$time,            
              siteID = new$siteID,
              obs_flag = 2, # not sure what this is for currently
              mean = pred_mean,
              sd = pred_sd,
              Conf_interv_02.5 = conf_int[1, ], #+ obs_conf_int[1, ],
              Conf_interv_97.5 = conf_int[3, ], #+ obs_conf_int[3, ],
              forecast = 1,
              data_assimilation = 0,
              x = x_new,
              obs = new$gcc_90,
              doy = new$doy)

  
ggplot(out, aes(x = doy, y = mean)) +
  geom_ribbon(aes(ymin = Conf_interv_02.5, ymax = Conf_interv_97.5), fill = "lightblue", alpha = 0.5) +
  geom_line() +
  facet_wrap(~siteID) +
  geom_point(aes(y = obs), color = "gray", alpha = 0.3) +
  labs(y = "Phenology DOY model")

out.2 <- out %>% 
  pivot_longer(mean:Conf_interv_97.5, 
               names_to = "statistic",
               values_to = "gcc_90") %>% 
  select(time, siteID, obs_flag, forecast, data_assimilation, statistic, gcc_90)


write.csv(out.2, paste0('phenology-', Sys.Date(), '-VT_Ph_GDD', '.csv'))

  
}


```


```{r}
# test the function by subsetting the existing dataset 

pheno <- read.csv('C:/Users/wwoel/Desktop/EF_class/phenology_data.csv')
forecast_start_date <- as.Date(max(pheno$time)) - 35
forecast_end_date <- as.Date(max(pheno$time))

pheno_forecast(data = pheno, 
               forecast_start_date = forecast_start_date,
               forecast_end_date = forecast_end_date)

```